[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! My name is Manuel and I am living in Switzerland. I have graduated in physics and currently I am working in IT. In this blog, I occasionally write about my hobby projects. Usually, you can expect to read about physics, electronics, math or computer science.\nThis website is built using the amazing Quarto publishing system. Its quarto source code can be found here."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html",
    "title": "Polygon Smoothing Riddle",
    "section": "",
    "text": "A random polygon evolves into an ellipse if we iteratively generate a new polygons with its edges being the center of the previous polygon: https://www.jasondavies.com/random-polygon-ellipse/\nThis phenomenon was recently brought forward in a notable but private discussion board by Dr. R. M. Of course, the following questions immediatley arise:\nWe try to address these in the following."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#definition",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#definition",
    "title": "Polygon Smoothing Riddle",
    "section": "Definition",
    "text": "Definition\nWe represent polygon points by numbers in the complex plane. This will turn out to lead to an elegant description of the phenomenon.\nThe averaging / smoothing of the polygon by calculating the point centers is implemented with\n\nimport numpy as np\n\ndef do_smoothing(points, steps):\n    \"\"\"Build average of neighboring points, apply it multiple times.\"\"\"\n    \n    for i in range(steps):\n        points = (points + np.roll(points, 1))/2 \n        \n    return points\n\nWe need to visualize a list of points as polygons in the following. We define this helper function by\n\nimport matplotlib.pyplot as plt\n\ndef show_points(points, ax=None, labels=True, dots=True, linewidth=0.5):\n    \"\"\"Plot all points in complex plane. If given, use the axis given, otherwise build new figure.\"\"\"\n    \n    X = [x.real for x in points]\n    Y = [x.imag for x in points]\n    X.append(X[0]) # start point is end point\n    Y.append(Y[0])\n    \n    if ax == None:\n        fig = plt.figure(figsize=[4,4])\n        ax = fig.add_subplot(111)\n        \n    ax.set_aspect('equal', 'datalim')\n\n    if dots: ax.scatter(X,Y, color='red')\n    ax.plot(X,Y, color='black', linewidth=linewidth)\n    \n    if labels:\n        for i in range(len(points)):\n            ax.annotate(i, (X[i], Y[i]), textcoords=\"offset points\", xytext=(0,10))"
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#polygon-evolution-example",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#polygon-evolution-example",
    "title": "Polygon Smoothing Riddle",
    "section": "Polygon Evolution Example",
    "text": "Polygon Evolution Example\nLet us reproduce the phenomenon with an example. A random polygon is chosen by\n\nN = 13\ninit_points = np.random.standard_normal(N) + np.random.standard_normal(N)*1j\nshow_points(init_points)\n\n\n\n\nLet the smoothing process evolve:\n\npoints = init_points\n\n# iterate smoothing:\nsteps = 3 # steps between plots\nplt.figure(figsize=[10,10]) \nfor i in range(16):\n    ax = plt.subplot(4,4,i+1)\n    show_points(points, ax)\n    points = do_smoothing(points, steps)\n\n\n\n\n\nAnswer to 2. Question\nWhy we observe 45° alignment can be answered here: We don’t observe that at all.\nThis peculiar alignment was an artifact of the zooming method which was used in [1]: While we iterate, the polygons get smaller in radius. If we zoom in X and Y direction independently, we will always make it look like being on a diagonal. The alignment is enforced by the zooming and has nothing to do with the smoothing procedure.\nAbove we use a uniform zoom factor (equal axis), which doesn’t break the rotation symmetry and thereby conserves to true alignment of the ellipse."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#prediction-of-final-ellipse",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#prediction-of-final-ellipse",
    "title": "Polygon Smoothing Riddle",
    "section": "Prediction of Final Ellipse",
    "text": "Prediction of Final Ellipse\nThe smoothing procedure is a linear operation which can be formulated in a matrix representation. \\[\\mathbb S \\, \\bf x_k = \\bf x_{k+1}\\]\nTo simplify the analysis, we can recall our QT lectures and do an eigenstate decomposition. Eigenstates (or eigenpolygons) do not change their shape shape under the smoothing operation but are only shrinked and rotated by a complex prefactor (eigenvalue).\n\\[ \\mathbb S \\, \\bf{ x} = \\lambda \\bf{ x} \\]\n\nDominant Eigenstates\nOf course we could do a more strict analysis, but let’s do it physicist free-style way (although Dr. S. wasn’t very happy with that…):\nWe found from numerical calculation (eigenstate analysis) of some polybon point numbers N, that circlular arrangements are eigenstates. They have the largest eigenvalue, i.e. they are the least suppressed/decreased in size from generation to generation, while all the other eigenstates converge faster to zero extend. We have observed this for N=3 and 5, so it must be a very general fact, right?\nTherefore, after a few iterations, circles are the only surviving contribution, everything else decreases much faster in size. So lets phrase the\nHypothesis: Circles are dominant eigenstates under the smoothing operation.\nThere are two independent cicular arrangments, namely\n\neigenstate1 = [np.exp(1j* 2*np.pi/N * k) for k in range(N)]  # clockwise orientation\neigenstate2 = [np.exp(-1j* 2*np.pi/N * k) for k in range(N)] # counter-clockwise orientation\n\nshow_points(eigenstate1, plt.subplot(121))\nshow_points(eigenstate2, plt.subplot(122))\n\n\n\n\nNote their clock/counter-clockwise orientation. Let’s check whether these are really eigenstates:\n\npoints = eigenstate1\n\n# iterate smoothing:\nn = 7\nplt.figure(figsize=[15,3]) \nfor i in range(n):\n    ax = plt.subplot(1,n,i+1)\n    show_points(points, ax)\n    points = do_smoothing(points, 1)\n\n\n\n\nApparently they are. They turn around, but that’s fine as it only is a complex prefactor introducing the turning and shrinking:\n\ndo_smoothing(eigenstate1, 1) / eigenstate1\n\narray([0.94272801-0.23236159j, 0.94272801-0.23236159j,\n       0.94272801-0.23236159j, 0.94272801-0.23236159j,\n       0.94272801-0.23236159j, 0.94272801-0.23236159j,\n       0.94272801-0.23236159j, 0.94272801-0.23236159j,\n       0.94272801-0.23236159j, 0.94272801-0.23236159j,\n       0.94272801-0.23236159j, 0.94272801-0.23236159j,\n       0.94272801-0.23236159j])\n\n\nWorks out as expected. we even get the eigenvalues for free.\n\neigenvalue1 = (do_smoothing(eigenstate1, 1) / eigenstate1)[0]\neigenvalue2 = (do_smoothing(eigenstate2, 1) / eigenstate2)[0]\n\neigenvalue1, eigenvalue2\n\n((0.9427280128266048-0.2323615860218846j),\n (0.9427280128266048+0.2323615860218846j))\n\n\n\n\nDecompose Initial State into Eigenstates\nIn order to find out how much of the eigenstates are included in our random initial state, we project the inital state onto the eigenvectors. This calls for the use of an inner product, which we readily have at hand with the familiar\n\ndef dot(v1, v2):\n    \"\"\"Dot Product between complex vectors\"\"\"\n    return np.dot(v1, np.conj(v2))\n\nLike in the good old QT days with Prof. H., we do first a normalization and check\n\neigenstate1 = eigenstate1 / np.sqrt(dot(eigenstate1, eigenstate1))\neigenstate2 = eigenstate2 / np.sqrt(dot(eigenstate2, eigenstate2))\n\ndot(eigenstate1, eigenstate1), dot(eigenstate2, eigenstate2)\n\n((1+0j), (1+0j))\n\n\nNicely normalized: Check. We can proceed:\nNow, let’s do the projection and get the complex coefficients\n\nc1 = dot(init_points, eigenstate1)\nc2 = dot(init_points, eigenstate2)\n\nc1, c2\n\n((0.5149093832008008-1.950855436819647j),\n (0.07602149507747744+1.113740507931655j))\n\n\nGood, both eigenstates seem to be present in there. What can we do with that?\n\n\nRepresentation as Ellipse\nAn general ellipse is parametrized by \\(\\varphi\\) with \\(a,b\\) being the half axis and \\(\\theta\\) a rotation angle. We define\n\ndef ellipse(a,b, phi, theta): \n    \"\"\"get coordinates of ellipse with half axes a,b rotated with theta, along parameter phi.\"\"\"\n    \n    c, s = a*np.cos(phi), b*np.sin(phi) \n    x = (s, c) # ellipse coordinate vector\n    \n    # rotate it\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array(((c, -s), (s, c))) # rotation matrix\n    x_rot = np.matmul(R, x)\n    \n    return x_rot[0] + 1j * x_rot[1] # go to complex representation\n\nAs our calculations show (they are still only on our window and wait to be transfered to the appendix in due time, of course), a superposition of both eigenstates result in a ellipse with the following parameters\n\\[ a = \\left|\\frac{|c_1| - |c_2|}{\\sqrt N}\\right|, \\quad b  = \\frac{|c_1| + |c_2|}{\\sqrt N} \\]\nand \\[ \\theta = \\frac{\\arg{c_1} + \\arg{c_2}}{2}\\]\nSo let’s give it a try:\n\nsteps = 300 # how many steps to iterate \n\n# propagete eigenstates through smoothing operation by mulitplying eigenvalue 'steps' times\nc1_it = c1 * np.power(eigenvalue1, steps)\nc2_it = c2 * np.power(eigenvalue2, steps)\n\n# magic, analytic formulas\na = np.abs(np.abs(c1_it) - np.abs(c2_it)) / np.sqrt(N) \nb = (np.abs(c1_it) + np.abs(c2_it)) / np.sqrt(N) \ntheta = (np.angle(c1_it) + np.angle(c2_it)) / 2\n\nellipse_pts = [ellipse(a, b, phi, theta) for phi in np.linspace(0, 2*np.pi, 50)]\n\nax = plt.subplot(111)\nshow_points(ellipse_pts, labels=False, dots=False, ax=ax, linewidth=2)\n\nshow_points(do_smoothing(init_points - np.mean(init_points), steps), labels=False,ax=ax)\n\n\n\n\nThe comparison between the predicted shape and iteratively computed point distribution is rather satisfying.\nAs an encore, we provide the comparison of the prediction based only on the two dominant eigenvalues in comparison to the computed iterated polygon:\n\ndef show_iteration_vs_dominantEigenstates(): \n    points = np.random.standard_normal(N) + np.random.standard_normal(N)*1j\n    points = points - np.mean(points)\n\n    c1 = dot(points, eigenstate1)\n    c2 = dot(points, eigenstate2)\n\n    steps = 3 # steps between plots\n\n    plt.figure(figsize=[10,10])\n\n    for i in range(16):\n        ax = plt.subplot(4, 4, i+1)\n        \n        # show smoothed points\n        show_points(points, ax, labels=False)\n\n        # now, calculate our analytic prediction ellipse for this iteration:\n\n        # propagete eigenstates through smoothing operation by mulitplying eigenvalue 'steps' times\n        c1_it = c1 * np.power(eigenvalue1, i*steps)\n        c2_it = c2 * np.power(eigenvalue2, i*steps)\n\n        a = np.abs(np.abs(c1_it) - np.abs(c2_it)) / np.sqrt(N)\n        b = (np.abs(c1_it) + np.abs(c2_it)) / np.sqrt(N)\n        theta = (np.angle(c1_it) + np.angle(c2_it)) / 2\n        ellipse_pts = [ellipse(a, b, phi, theta) for phi in np.linspace(0, 2*np.pi, 50)]\n\n        show_points(ellipse_pts, labels=False, dots=False, ax=ax, linewidth=2)\n\n        # for next iteration, do smoothing\n        points = do_smoothing(points, steps)\n        \nshow_iteration_vs_dominantEigenstates()\n\n\n\n\nWe see, how the dominant eigenstates start to fully describe the evolution."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#enforcement-of-circular-convergence",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#enforcement-of-circular-convergence",
    "title": "Polygon Smoothing Riddle",
    "section": "Enforcement of Circular Convergence",
    "text": "Enforcement of Circular Convergence\nComparison before and after “Face-lifting”:\n\ninit_points = np.random.standard_normal(N) + np.random.standard_normal(N)*1j\n\ninit_points_facelifted = init_points - dot(init_points, eigenstate1) * eigenstate1 \n# eigenstate1 is hereby fully removed, only eigenstate2 and the other contributions survive\n\nshow_points(init_points, plt.subplot(121))\nshow_points(init_points_facelifted, plt.subplot(122))\n\n\n\n\nLet it roll…\n\nsteps = 4 # steps between plots\n\npoints = init_points_facelifted\n\nplt.figure(figsize=[10,10]) \nfor i in range(16):\n    ax = plt.subplot(4,4,i+1)\n    show_points(points, ax)\n    points = do_smoothing(points, steps)\n\n\n\n\nAmazingly, here you have your ordered circle.\nHomework Exercise: How about a counter-clockwise arrangement? :-)\n\nAnswer to Question 3\nWe can conclude, that the following must be given in order to converge into a circle: Only clockwiseness or only counter-clockwiseness must be included in your start polygon, then it will evolve into a circle. While these terms are not well established in the community yet, we are confident that our work will have its impact here."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#conclusions-and-acknowledgments",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#conclusions-and-acknowledgments",
    "title": "Polygon Smoothing Riddle",
    "section": "Conclusions and Acknowledgments",
    "text": "Conclusions and Acknowledgments\nDear reader, thank you for your appreciated attention!\nWith that we would like to thank for all inspirational inputs from our “physicist” friends!\nYours sincerly, L. and M."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#shift-invariance",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#shift-invariance",
    "title": "Polygon Smoothing Riddle",
    "section": "Shift Invariance",
    "text": "Shift Invariance\nIf we go on step further in analysis, we can readily observe that we not only have a linear operation, but a translation invariant: If we shift the indizes of the point of input state, the smoothing process \\(\\mathbb S\\) will yield the same output as before, but with this output after the index shift. Index shift denoted by \\(\\mathcal R\\) and smoothing operation \\(\\mathbb S\\) commute:\n\\[ \\vec x = (x_1, x_2, ... x_N), \\, \\mathcal R\\,\\vec x = \\vec x' = (x_2, x_3, ... x_N, x_1):  \\quad \\mathcal R (\\mathbb S\\,\\vec x) =  \\mathbb S (\\mathcal R \\,\\vec x) = \\frac 1 2 (x_2+x_3, x_3+x_4, ...)\\]\nA general shift-invariant linear operation on continous functions are given by convolutions \\[ (f \\ast g)(x) \\doteq \\int \\,dy\\, g(y)\\,f(x-y) = h(x), \\quad f(x+\\Delta x) \\ast g(x) = h'(x) = h(x+\\Delta x)\\]\nThe convolution Fourier theorem tells us, that their corresponding Fourier transforms \\(f(x) = \\int\\,dk\\, \\tilde{f}(k)\\, \\exp(ikx)\\), …, are related by a simple multiplication\n\\[ \\tilde{f}(k) \\, \\tilde{g}(k) = \\tilde{h}(k) \\]\nThis is an interesting fact and allows to write a convolution in much simpler terms. Let’s try to apply this to our case."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#discrete-fourier-transforms-dft-theory",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#discrete-fourier-transforms-dft-theory",
    "title": "Polygon Smoothing Riddle",
    "section": "Discrete Fourier Transforms (DFT) Theory",
    "text": "Discrete Fourier Transforms (DFT) Theory\nAs phycisists, we are well experienced with the continous Fourier transform. But we obviously dont have an continous function but discrete points \\((x_1, x_2, ... x_n)\\). Here is a short intro to the discret case. DFT is a very common tool in digital signal processing where the signal is sampled at a fixed frequency…\n\nDiscretness\nLet’s define \\(f(d), d \\in \\mathbb Z\\). This simplifies the Fourier transform to\n\\[f(d) = \\int^{2\\pi}_{0}dk\\, \\tilde{f}(k)\\, \\exp(ikd)\\]\nIntuition: The wavevector spectrum is limited to \\(0...2\\pi\\). Any oscillation faster than “one oscillation per 1 unit” is not needed, as we only evalute \\(f(d)\\) at integer \\(d\\). (This result is known as Nyquist-Shannon theorem and can be gained in a more formal way by multiplying a general \\(f(x)\\) with a Dirac comb which results in the mentioned consequences in wavevector spectrum).\n\n\nFiniteness\nThe above results still assumed an umlimited number of points involved. Without loss of generality, we can define \\(f(d)\\) periodic, such that \\(f(d) = f(d+N)\\) holds. We limit the function to \\(N\\) different values. In general, a periodic function, like the newly defined \\(f(d)\\), can be represented with a discrete Fourier series\n\\[ f(x) = \\sum_{k=-\\inf}^{\\inf}\\, a(k) \\, e^{i\\frac{2\\pi k}{N} x}, \\quad a(k) \\in \\mathbb C .\\]\nIntuition: Only wavevectors with wavelenghts = repetion cycles which are integer fractions of the function cycle length \\(N\\), i.e. cycles which repeat after length \\(N\\), are present.\n\n\nDiscrete and Finite -&gt; DFT\nTaking both results, we ariive at the conclusion, that\n\\[ f(d) = \\sum_{k=0}^{N-1}\\, a(k) \\, e^{i\\frac{2\\pi k}{N} d} \\]\nwhere the coefficients \\(a(k) = \\tilde{f}(k), \\, k \\in \\{0, \\ldots, N-1\\}\\) are the discrete Fourier transform of \\(f(d)\\).\nWe can explicitly calculate for two summands\n\\[ \\sum_{d=0}^{N-1}  e^{i\\frac{2\\pi k}{N} d}  e^{-i\\frac{2\\pi k'}{N} d} = N \\delta_{k-k'} \\]\nand thereby observe the orthogonality of different terms which is well known in the continous case (where a Dirac delta function is used).\n\n\nDiscrete Convolution\nIn analogy to the continous case, a discrete, cylic convolution can be defined by\n\\[ (f \\ast g) (d) = \\sum_{d'=0}^{N-1} g(d') f(d-d') \\]\nwhere we assumed \\(f(d)\\) to be periodic. By explicitly calculating, we find \\[ (f \\ast g) (d)  = \\sum_{d'=0}^{N-1} \\left(\\sum_{k=0}^{N-1}\\, \\tilde g(k) \\, e^{i\\frac{2\\pi k}{N} d'}\\right) \\left(\\sum_{k'=0}^{N-1}\\, \\tilde f(k') \\, e^{i\\frac{2\\pi k'}{N} (d-d')}\\right)\n= \\sum_{k=0}^{N-1} \\sum_{k'=0}^{N-1}\\, \\tilde g(k) \\, \\tilde f(k') \\, \\sum_{d'=0}^{N-1} e^{i\\frac{2\\pi k}{N} d'} e^{i\\frac{2\\pi k'}{N} (d-d')} \\]\nEvaluating the sum over \\(d'\\) and using the orthogonality condition found above, we find a \\(N\\delta_{k-k'}\\) and therefore\n\\[ (f \\ast g) (d)  = N\\,\\sum_{k=0}^{N-1} \\tilde g(k) \\, \\tilde f(k) \\, e^{i\\frac{2\\pi k}{N} d} .\\]\nThis is the equivalent result to the continous case: The convolution is a mutliplication in Fourier space."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#polygon-smoothing-as-discrete-convolution",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#polygon-smoothing-as-discrete-convolution",
    "title": "Polygon Smoothing Riddle",
    "section": "Polygon Smoothing as Discrete Convolution",
    "text": "Polygon Smoothing as Discrete Convolution\nIf we chose\n\\[ f(d)  \\doteq x_{d-1}, \\, d \\in {0, \\ldots, N-1}, \\quad  g(0)= g(1) \\doteq \\frac 1 2, \\, g(d) \\doteq 0, \\, d \\in \\{2,\\ldots, N\\}\\]\nand furthermore impose periodicity with \\(f(d+N) = f(d)\\), equally on \\(g(d)\\), both function are defined over \\(\\mathbb Z\\), but represent \\(N\\) independent complex points. With and the above defined discrete convolution, we find\n\\[ (f \\ast g) (d) = \\sum_{d'=0}^{N-1} g(d') f(d-d') = h(d) = \\frac{x_d+x_{d-1}} 2 \\]\nWe observe that this corresponds to our smoothing/averaging process \\(\\mathbb S\\)! It is a moving averaging operation performed on the set of points.\nThe Fourier convolution theorem tells us, that this linear, shift-invariant operation can be written in this discrete case with the transforms\n\\[ \\tilde{h}(k) = N \\tilde{f}(k)\\,\\tilde{g}(k), \\, k \\in \\{0,N-1\\}\\]\nIf we iterate \\(G\\) times through the smooting, we arrive at the simple result \\[ \\tilde{h}(k) = \\tilde{f}(k)\\,(N\\tilde{g}(k))^{G}\\]\nThis fully determines the evolution. If \\(N|\\tilde g(k)|&lt;1\\), the components at given \\(k\\) are increasingly suppressed. With this, we got all eigenstates of the smoothign operation for free: They are apparatly the Fourier components of different \\(k\\)."
  },
  {
    "objectID": "posts/polygon-smoothing/PolygonSmoothing.html#numeric-illustration",
    "href": "posts/polygon-smoothing/PolygonSmoothing.html#numeric-illustration",
    "title": "Polygon Smoothing Riddle",
    "section": "Numeric Illustration",
    "text": "Numeric Illustration\n\nN = 13\ninitial_points = np.random.standard_normal(N) + np.random.standard_normal(N)*1j\nf = initial_points\n\nLet’s generate to above defined \\(g(d)\\) with\n\ng = np.zeros(N)\ng[[0,1]] = 1/2\nprint(g)\n\n[0.5 0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n\n\nLet Python calculate the DFT, as defined above, using FFT functions\n\nf_tilde = np.fft.ifft(f)\ng_tilde = np.fft.ifft(g)\n\nThe smoothing iteration using the convolution theorem is illustrated here togehter with the Fourier transform:\n\nsteps_per_image = 10\nn = 5\n\nplt.figure(figsize=[25,5]) \nfor i in range(n):\n    \n    h_tilde = np.multiply(f_tilde, np.power(N*abs(g_tilde), i*steps_per_image)) # according to convolution fourier theorem, see above\n    h = np.fft.fft(h_tilde)\n\n    ax = plt.subplot(2,n,i+1)\n    ax.set_title(\"$\\\\tilde h(k)$\")\n    ax.bar(range(N),abs(h_tilde))\n    \n    ax = plt.subplot(2,n,i+n+1)\n    ax.set_title(\"$f(d)$\")\n    show_points(h, ax=ax)  \n\n\n\n\nThings seemt to work out\n\nInterpretation\nAs abovious from the multiplication factor \\(\\tilde g(k)\\):\n\nplt.plot(N*abs(g_tilde))\n\n\n\n\noscillations \\(k=0, 1\\) and \\(N-1\\) are dominant. All other are suppressed stronger and damped out in the iteration shown above.\nAs can be seen in the DFT defition, \\(k=0\\) corresponds to a constant, which here represents the center of gravity of the points which does not change through iterations: \\(\\tilde g(0) = 1\\). \\(k=1\\) and \\(N-1\\) are the already known clockwise and counterclockwise circles. If added up in a linear combination, they result in an ellipse.\nAll the other Fourier terms are circles as well, but with winding number \\(W\\) larger than one. Just a few examples:\n\nplt.figure(figsize=[25,4]) \nws = range(-1,5)\nfor i, w in enumerate(ws):\n    ax = plt.subplot(1,len(ws), i+1)\n    ax.set_title(\"W = \" + str(w))\n    \n    a = np.zeros(N)\n    a[w % N] = 1\n    h = np.fft.ifft(a)\n    \n    print(a)\n    show_points(h, ax=ax)\n\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n\n\n\n\n\nInsofar, we have to correct our answer above: we arrive at pure circles of only winding number \\(W=1\\) or -1 are present, not both. But any higher wining number of any sign (clockwise or counter clockwise) will be damped away anyways.\nGeometrically, this is obvious: the more curved, the stronger diminished are the shapes in the smoothing process.\nWith that, we finally and ultimatley conclude :-)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Polygon Smoothing Riddle\n\n\n\n\n\n\n\nmath\n\n\n\n\nWe analyze a geometrical phenomenon appearing in an averaging procedure performed on polygons. Linear algebra and Fourier analysis methods give insights into the mechanism.\n\n\n\n\n\n\nApr 27, 2020\n\n\nManuel and Laura\n\n\n\n\n\n\nNo matching items"
  }
]